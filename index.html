<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MoodSync - AI Facial Expression Analysis</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/4.10.0/tf.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/face-api.js/0.22.2/face-api.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
        }

        .header {
            text-align: center;
            margin-bottom: 30px;
        }

        .header h1 {
            color: #333;
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .ml-badge {
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.9em;
            display: inline-block;
            margin-bottom: 20px;
        }

        .video-section {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-bottom: 30px;
        }

        .camera-container {
            position: relative;
            background: #000;
            border-radius: 15px;
            overflow: hidden;
            aspect-ratio: 4/3;
        }

        #videoElement {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        #overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-top: 15px;
            flex-wrap: wrap;
        }

        .control-btn {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: transform 0.2s;
        }

        .control-btn:hover {
            transform: translateY(-2px);
        }

        .control-btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .analysis-panel {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 25px;
            height: fit-content;
        }

        .status-indicator {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 20px;
            padding: 12px;
            border-radius: 8px;
            font-weight: 600;
        }

        .status-loading {
            background: #fff3cd;
            color: #856404;
        }

        .status-active {
            background: #d1edff;
            color: #0c5460;
        }

        .status-error {
            background: #f8d7da;
            color: #721c24;
        }

        .emotion-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
            gap: 15px;
            margin-bottom: 25px;
        }

        .emotion-card {
            background: white;
            padding: 15px;
            border-radius: 10px;
            text-align: center;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            transition: transform 0.2s;
        }

        .emotion-card:hover {
            transform: translateY(-2px);
        }

        .emotion-icon {
            font-size: 2em;
            margin-bottom: 8px;
        }

        .emotion-name {
            font-weight: 600;
            color: #333;
            margin-bottom: 5px;
        }

        .emotion-confidence {
            font-size: 0.9em;
            color: #666;
        }

        .confidence-bar {
            width: 100%;
            height: 6px;
            background: #e0e0e0;
            border-radius: 3px;
            overflow: hidden;
            margin-top: 5px;
        }

        .confidence-fill {
            height: 100%;
            background: linear-gradient(45deg, #667eea, #764ba2);
            transition: width 0.3s;
        }

        .metrics-section {
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin-top: 20px;
        }

        .metric-row {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px 0;
            border-bottom: 1px solid #eee;
        }

        .metric-row:last-child {
            border-bottom: none;
        }

        .mood-timeline {
            background: white;
            padding: 20px;
            border-radius: 15px;
            margin-top: 30px;
        }

        .timeline-chart {
            width: 100%;
            height: 200px;
            margin-top: 15px;
        }

        .loading-spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .model-info {
            background: #e9ecef;
            padding: 15px;
            border-radius: 8px;
            margin-top: 20px;
            font-size: 0.9em;
            color: #495057;
        }

        .detection-stats {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 15px;
            margin: 20px 0;
        }

        .stat-card {
            background: white;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .stat-value {
            font-size: 1.5em;
            font-weight: bold;
            color: #667eea;
        }

        .stat-label {
            font-size: 0.9em;
            color: #666;
            margin-top: 5px;
        }

        @media (max-width: 768px) {
            .video-section {
                grid-template-columns: 1fr;
            }
            
            .controls {
                flex-direction: column;
                align-items: center;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>MoodSync</h1>
            <div class="ml-badge">ü§ñ Real-time Facial Expression AI</div>
            <p>Advanced computer vision and deep learning for emotion recognition</p>
        </div>

        <div class="video-section">
            <div>
                <div class="camera-container">
                    <video id="videoElement" autoplay muted playsinline></video>
                    <canvas id="overlay"></canvas>
                </div>
                <div class="controls">
                    <button id="startBtn" class="control-btn" onclick="startCamera()">
                        üìπ Start Camera
                    </button>
                    <button id="stopBtn" class="control-btn" onclick="stopCamera()" disabled>
                        ‚èπÔ∏è Stop Camera
                    </button>
                    <button id="captureBtn" class="control-btn" onclick="captureEmotion()" disabled>
                        üì∏ Capture Analysis
                    </button>
                </div>
            </div>

            <div class="analysis-panel">
                <div id="status" class="status-indicator status-loading">
                    <div class="loading-spinner"></div>
                    <span>Loading AI models...</span>
                </div>

                <div class="emotion-grid" id="emotionGrid">
                    <!-- Emotion cards will be populated by JavaScript -->
                </div>

                <div class="detection-stats">
                    <div class="stat-card">
                        <div class="stat-value" id="faceCount">0</div>
                        <div class="stat-label">Faces Detected</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-value" id="confidenceAvg">0%</div>
                        <div class="stat-label">Avg Confidence</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-value" id="frameRate">0</div>
                        <div class="stat-label">FPS</div>
                    </div>
                </div>

                <div class="metrics-section">
                    <h3>Facial Analysis Metrics</h3>
                    <div class="metric-row">
                        <span>Dominant Emotion:</span>
                        <strong id="dominantEmotion">-</strong>
                    </div>
                    <div class="metric-row">
                        <span>Expression Intensity:</span>
                        <strong id="expressionIntensity">-</strong>
                    </div>
                    <div class="metric-row">
                        <span>Face Landmarks:</span>
                        <strong id="landmarkCount">-</strong>
                    </div>
                    <div class="metric-row">
                        <span>Age Estimate:</span>
                        <strong id="ageEstimate">-</strong>
                    </div>
                    <div class="metric-row">
                        <span>Gender Prediction:</span>
                        <strong id="genderPrediction">-</strong>
                    </div>
                </div>
            </div>
        </div>

        <div class="mood-timeline">
            <h3>üìä Real-time Emotion Timeline</h3>
            <canvas id="emotionChart" class="timeline-chart"></canvas>
        </div>

        <div class="model-info">
            <h4>üß† AI Model Architecture</h4>
            <p><strong>Face Detection:</strong> SSD MobileNet v1 | <strong>Expression Analysis:</strong> CNN with 68 facial landmarks | <strong>Emotion Classification:</strong> 7-class deep learning model trained on FER2013 dataset</p>
        </div>
    </div>

    <script>
        // Global variables
        let video;
        let canvas;
        let ctx;
        let isModelLoaded = false;
        let isStreaming = false;
        let animationId;
        let emotionHistory = [];
        let frameCount = 0;
        let lastFrameTime = Date.now();

        // Emotion labels and their corresponding emojis
        const emotionConfig = {
            'neutral': { emoji: 'üòê', color: '#95a5a6' },
            'happy': { emoji: 'üòä', color: '#f39c12' },
            'sad': { emoji: 'üò¢', color: '#3498db' },
            'angry': { emoji: 'üò†', color: '#e74c3c' },
            'fearful': { emoji: 'üò®', color: '#9b59b6' },
            'disgusted': { emoji: 'ü§¢', color: '#1abc9c' },
            'surprised': { emoji: 'üò≤', color: '#e67e22' }
        };

        // Initialize the application
        async function initializeApp() {
            try {
                updateStatus('Loading AI models...', 'loading');
                
                // Load face-api.js models
                await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights/');
                await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights/');
                await faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights/');
                await faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights/');
                await faceapi.nets.ageGenderNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@master/weights/');

                isModelLoaded = true;
                updateStatus('AI models loaded successfully! Click Start Camera to begin.', 'active');
                
                // Initialize emotion grid
                initializeEmotionGrid();
                
                // Initialize chart
                initializeChart();
                
                console.log('Face-API models loaded successfully');
                
            } catch (error) {
                console.error('Error loading models:', error);
                updateStatus('Error loading AI models. Please refresh the page.', 'error');
            }
        }

        function updateStatus(message, type) {
            const status = document.getElementById('status');
            status.className = `status-indicator status-${type}`;
            
            const spinner = type === 'loading' ? '<div class="loading-spinner"></div>' : '';
            status.innerHTML = `${spinner}<span>${message}</span>`;
        }

        function initializeEmotionGrid() {
            const grid = document.getElementById('emotionGrid');
            grid.innerHTML = '';
            
            Object.entries(emotionConfig).forEach(([emotion, config]) => {
                const card = document.createElement('div');
                card.className = 'emotion-card';
                card.innerHTML = `
                    <div class="emotion-icon">${config.emoji}</div>
                    <div class="emotion-name">${emotion.charAt(0).toUpperCase() + emotion.slice(1)}</div>
                    <div class="emotion-confidence" id="${emotion}-confidence">0%</div>
                    <div class="confidence-bar">
                        <div class="confidence-fill" id="${emotion}-bar" style="width: 0%"></div>
                    </div>
                `;
                grid.appendChild(card);
            });
        }

        async function startCamera() {
            if (!isModelLoaded) {
                alert('AI models are still loading. Please wait a moment.');
                return;
            }

            try {
                video = document.getElementById('videoElement');
                canvas = document.getElementById('overlay');
                ctx = canvas.getContext('2d');

                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        width: { ideal: 640 },
                        height: { ideal: 480 },
                        facingMode: 'user'
                    }
                });

                video.srcObject = stream;
                
                video.addEventListener('loadedmetadata', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    startDetection();
                });

                isStreaming = true;
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                document.getElementById('captureBtn').disabled = false;
                
                updateStatus('Camera active - Real-time emotion analysis running', 'active');

            } catch (error) {
                console.error('Error accessing camera:', error);
                updateStatus('Error accessing camera. Please check permissions.', 'error');
            }
        }

        function stopCamera() {
            if (video && video.srcObject) {
                const tracks = video.srcObject.getTracks();
                tracks.forEach(track => track.stop());
                video.srcObject = null;
            }

            if (animationId) {
                cancelAnimationFrame(animationId);
            }

            isStreaming = false;
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            document.getElementById('captureBtn').disabled = true;
            
            updateStatus('Camera stopped', 'loading');
            
            // Clear canvas
            if (ctx) {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
            }
        }

        async function startDetection() {
            if (!isStreaming) return;

            try {
                // Detect faces with expressions, age, and gender
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceExpressions()
                    .withAgeAndGender();

                // Clear canvas
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                // Update statistics
                updateStatistics(detections);

                // Draw detections
                drawDetections(detections);

                // Update emotion displays
                if (detections.length > 0) {
                    updateEmotionDisplay(detections[0]);
                    updateMetrics(detections[0]);
                    recordEmotionHistory(detections[0]);
                }

                // Calculate FPS
                frameCount++;
                const currentTime = Date.now();
                if (currentTime - lastFrameTime >= 1000) {
                    const fps = Math.round(frameCount * 1000 / (currentTime - lastFrameTime));
                    document.getElementById('frameRate').textContent = fps;
                    frameCount = 0;
                    lastFrameTime = currentTime;
                }

            } catch (error) {
                console.error('Detection error:', error);
            }

            animationId = requestAnimationFrame(startDetection);
        }

        function drawDetections(detections) {
            detections.forEach(detection => {
                const { box } = detection.detection;
                
                // Draw bounding box
                ctx.strokeStyle = '#667eea';
                ctx.lineWidth = 2;
                ctx.strokeRect(box.x, box.y, box.width, box.height);
                
                // Draw landmarks
                if (detection.landmarks) {
                    ctx.fillStyle = '#764ba2';
                    detection.landmarks.positions.forEach(point => {
                        ctx.beginPath();
                        ctx.arc(point.x, point.y, 1, 0, 2 * Math.PI);
                        ctx.fill();
                    });
                }

                // Draw emotion label
                const dominantEmotion = getDominantEmotion(detection.expressions);
                if (dominantEmotion) {
                    ctx.fillStyle = 'rgba(102, 126, 234, 0.8)';
                    ctx.fillRect(box.x, box.y - 30, box.width, 25);
                    
                    ctx.fillStyle = 'white';
                    ctx.font = '14px Arial';
                    ctx.textAlign = 'center';
                    ctx.fillText(
                        `${dominantEmotion.emotion} (${(dominantEmotion.confidence * 100).toFixed(1)}%)`,
                        box.x + box.width / 2,
                        box.y - 10
                    );
                }
            });
        }

        function updateStatistics(detections) {
            document.getElementById('faceCount').textContent = detections.length;
            
            if (detections.length > 0) {
                const avgConfidence = detections.reduce((sum, detection) => {
                    const dominant = getDominantEmotion(detection.expressions);
                    return sum + (dominant ? dominant.confidence : 0);
                }, 0) / detections.length;
                
                document.getElementById('confidenceAvg').textContent = `${(avgConfidence * 100).toFixed(1)}%`;
            } else {
                document.getElementById('confidenceAvg').textContent = '0%';
            }
        }

        function updateEmotionDisplay(detection) {
            Object.entries(detection.expressions).forEach(([emotion, confidence]) => {
                const confidenceElement = document.getElementById(`${emotion}-confidence`);
                const barElement = document.getElementById(`${emotion}-bar`);
                
                if (confidenceElement && barElement) {
                    confidenceElement.textContent = `${(confidence * 100).toFixed(1)}%`;
                    barElement.style.width = `${confidence * 100}%`;
                }
            });
        }

        function updateMetrics(detection) {
            const dominant = getDominantEmotion(detection.expressions);
            document.getElementById('dominantEmotion').textContent = 
                dominant ? `${dominant.emotion} (${(dominant.confidence * 100).toFixed(1)}%)` : '-';
            
            const intensity = Math.max(...Object.values(detection.expressions));
            document.getElementById('expressionIntensity').textContent = `${(intensity * 100).toFixed(1)}%`;
            
            document.getElementById('landmarkCount').textContent = detection.landmarks ? '68 points' : '-';
            
            if (detection.age && detection.gender) {
                document.getElementById('ageEstimate').textContent = `${Math.round(detection.age)} years`;
                document.getElementById('genderPrediction').textContent = 
                    `${detection.gender} (${(detection.genderProbability * 100).toFixed(1)}%)`;
            }
        }

        function getDominantEmotion(expressions) {
            let maxConfidence = 0;
            let dominantEmotion = null;
            
            Object.entries(expressions).forEach(([emotion, confidence]) => {
                if (confidence > maxConfidence) {
                    maxConfidence = confidence;
                    dominantEmotion = { emotion, confidence };
                }
            });
            
            return dominantEmotion;
        }

        function recordEmotionHistory(detection) {
            const dominant = getDominantEmotion(detection.expressions);
            if (dominant) {
                emotionHistory.push({
                    timestamp: Date.now(),
                    emotion: dominant.emotion,
                    confidence: dominant.confidence,
                    expressions: { ...detection.expressions }
                });
                
                // Keep only last 50 entries
                if (emotionHistory.length > 50) {
                    emotionHistory.shift();
                }
                
                updateChart();
            }
        }

        function initializeChart() {
            const canvas = document.getElementById('emotionChart');
            const ctx = canvas.getContext('2d');
            canvas.width = canvas.offsetWidth;
            canvas.height = canvas.offsetHeight;
        }

        function updateChart() {
            const canvas = document.getElementById('emotionChart');
            const ctx = canvas.getContext('2d');
            
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            if (emotionHistory.length < 2) return;
            
            // Draw emotion confidence over time
            const emotions = Object.keys(emotionConfig);
            const colors = Object.values(emotionConfig).map(config => config.color);
            
            emotions.forEach((emotion, index) => {
                ctx.strokeStyle = colors[index];
                ctx.lineWidth = 2;
                ctx.beginPath();
                
                emotionHistory.forEach((entry, i) => {
                    const x = (i / (emotionHistory.length - 1)) * canvas.width;
                    const y = canvas.height - (entry.expressions[emotion] * canvas.height);
                    
                    if (i === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }
                });
                
                ctx.stroke();
            });
            
            // Draw legend
            emotions.forEach((emotion, index) => {
                const y = 20 + index * 15;
                ctx.fillStyle = colors[index];
                ctx.fillRect(10, y - 5, 10, 10);
                ctx.fillStyle = '#333';
                ctx.font = '12px Arial';
                ctx.fillText(emotion, 25, y + 3);
            });
        }

        async function captureEmotion() {
            if (!isStreaming) return;
            
            try {
                // Take a snapshot for analysis
                const canvas = document.createElement('canvas');
                const context = canvas.getContext('2d');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                context.drawImage(video, 0, 0);
                
                // Perform detailed analysis
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceExpressions()
                    .withAgeAndGender();
                
                if (detections.length > 0) {
                    const detection = detections[0];
                    const dominant = getDominantEmotion(detection.expressions);
                    
                    alert(`üì∏ Emotion Captured!\n\nDominant Emotion: ${dominant.emotion}\nConfidence: ${(dominant.confidence * 100).toFixed(1)}%\nAge: ~${Math.round(detection.age)} years\nGender: ${detection.gender}`);
                } else {
                    alert('No face detected in the current frame. Please ensure your face is visible.');
                }
                
            } catch (error) {
                console.error('Capture error:', error);
                alert('Error capturing emotion. Please try again.');
            }
        }

        // Initialize the application when the page loads
        window.addEventListener('load', initializeApp);

        // Handle page unload
        window.addEventListener('beforeunload', () => {
            if (isStreaming) {
                stopCamera();
            }
        });
    </script>
</body>
</html>
